{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f37207d-3f8e-43a4-8f27-e190c52443b8",
   "metadata": {},
   "source": [
    "<h3>Testing Notebook</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f54b69c-520d-4636-912d-3622d2e0fa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4161d1f-8e2a-404d-9d70-26088dc75927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "63af8126-651f-4b4c-b911-4149d2f6c0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "ligands = [\"TNF\", \"R84\", \"PIC\", \"P3K\", \"FLA\", \"CpG\", \"FSL\", \"LPS\", \"UST\"]\n",
    "polarization = [\"\", \"ib\", \"ig\", \"i0\", \"i3\", \"i4\"]\n",
    "replicas, size = 2, 1288 # replicated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db49037a-3cf4-4ef8-9c2b-c6a5989999e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.getdata import *\n",
    "from core.dataset import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decfae6b-d66b-438f-926e-726468b45878",
   "metadata": {},
   "source": [
    "<h3>Example of GetData</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "857176ea-c822-4ef4-99ba-6f5dea763833",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1288, 98)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TNFib1 = GetData(ligands[0], polarization[1], replicas, size)\n",
    "TNFib1.X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a347ad7-6d34-4e08-8547-e5aca2b0cf86",
   "metadata": {},
   "source": [
    "<h3>Example of Dataset</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d8c34e5-076a-4a4d-b10a-208fb24729a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DatasetPolar(ligands, polarization, replicas, size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "54d2e8d3-6af1-4da3-ae73-6390e1e422a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 38 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for _ in data:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "55cbc610-dbf0-4aa0-a919-a0e33a887d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69552, 98, 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0f61405-e394-4a9d-a872-727aee3b392e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data.data), type(data.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b728e40-cb9f-4d34-973e-393bc4c3fc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 8 8 8] (69552,)\n"
     ]
    }
   ],
   "source": [
    "print(data.labels, data.labels.shape) #labels are multi-hot encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1528860b-18b7-4501-a9e6-af504b5d59f3",
   "metadata": {},
   "source": [
    "<h3>Initializing Dataloaders</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36f86ae4-56ee-4a59-8e86-2e0be1fb5e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0511860-f810-40ed-905d-950f9f31103b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62596 6955 56336 6259\n",
      "69551 69552\n"
     ]
    }
   ],
   "source": [
    "X_len, test_len = int(len(data.data) * 0.9), int(len(data.data) * 0.1)\n",
    "train_len, val_len = int(X_len * 0.9), int(X_len * 0.1)\n",
    "print(X_len, test_len, train_len, val_len) #lengths\n",
    "print(X_len + test_len, len(data.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0ce3d948-86dd-49e2-9fac-c73dcb735e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = data.data.reshape(data.data.shape[0], data.data.shape[1], 1) #adds extra dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec07a63b-10fc-4ee4-b18b-f1bbe21c6a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69552"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.data[1000].shape\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b32d6314-dd53-43bf-b25f-37704741b435",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_X, dataset_val = torch.utils.data.random_split(data, [X_len, test_len+1]) # still np arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7ac0a68b-692a-4773-b83e-3ede14b768fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader_train = torch.utils.data.DataLoader(dataset_X, batch_size=64, shuffle=True)\n",
    "dataloader_val = torch.utils.data.DataLoader(dataset_val, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "387ae2bf-5805-4fa9-8f89-6007a41bd539",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "979 109 1088\n"
     ]
    }
   ],
   "source": [
    "print(len(dataloader_train), len(dataloader_val), len(dataloader_train) + len(dataloader_val))\n",
    "###\n",
    "#data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de10af5-c1e5-4a20-bbbc-27ace3667ad2",
   "metadata": {},
   "source": [
    "<h3>Model Training</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d43ece0f-9510-4728-a520-05da75c50218",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.network import *\n",
    "from core.trainer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "900bf9d3-f6eb-490b-9135-5bef35147077",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a6573c04-8653-4dfd-8d96-5542d2860e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model parameters\n",
    "input_size = 1\n",
    "hidden_sizes = 98\n",
    "output_size = 9\n",
    "\n",
    "#training parameters\n",
    "n_epochs = 50\n",
    "batch_size = 64\n",
    "learning_rate = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5a41d15a-a573-45a3-9a2b-a0d881b2bf66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM(\n",
       "  (lstm): LSTM(98, 98, batch_first=True)\n",
       "  (fc1): Linear(in_features=98, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM(input_size, hidden_sizes, output_size, num_layers=1, device=\"cuda:0\")\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "03d3fe18-57c0-422f-8169-4cf119dd9ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = LSTMTrainer(model=model, device=\"cuda:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5a666ce0-520c-4250-a9f8-75ba180ec404",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                           | 0/50 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "input.size(-1) must be equal to input_size. Expected 98, got 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6524/777513220.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloader_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Research\\hoffmanlab\\timeseriesmodel\\notebooks\\extras\\../..\\core\\trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, dataloader_train, dataloader_val, batch_size, n_epochs)\u001b[0m\n\u001b[0;32m     46\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     47\u001b[0m                 \u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 48\u001b[1;33m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m                 \u001b[0mbatch_losses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Research\\hoffmanlab\\timeseriesmodel\\notebooks\\extras\\../..\\core\\trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[1;34m(self, x, y)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\peep\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Research\\hoffmanlab\\timeseriesmodel\\notebooks\\extras\\../..\\core\\network.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# If we don't, we'll backprop all the way to the start even after going through another batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m# Forward propagation by passing in the input, hidden state, and cell state into the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcn\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mh0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[1;31m# Reshaping the outputs in the shape of (batch_size, seq_length, hidden_size)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\peep\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1102\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1103\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\miniconda3\\envs\\peep\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, hx)\u001b[0m\n\u001b[0;32m    687\u001b[0m             \u001b[0mhx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpermute_hidden\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msorted_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_forward_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    690\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n",
      "\u001b[1;32m~\\miniconda3\\envs\\peep\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_forward_args\u001b[1;34m(self, input, hidden, batch_sizes)\u001b[0m\n\u001b[0;32m    630\u001b[0m                            \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    631\u001b[0m                            ):\n\u001b[1;32m--> 632\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sizes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    633\u001b[0m         self.check_hidden_size(hidden[0], self.get_expected_hidden_size(input, batch_sizes),\n\u001b[0;32m    634\u001b[0m                                'Expected hidden[0] size {}, got {}')\n",
      "\u001b[1;32m~\\miniconda3\\envs\\peep\\lib\\site-packages\\torch\\nn\\modules\\rnn.py\u001b[0m in \u001b[0;36mcheck_input\u001b[1;34m(self, input, batch_sizes)\u001b[0m\n\u001b[0;32m    203\u001b[0m                     expected_input_dim, input.dim()))\n\u001b[0;32m    204\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_size\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             raise RuntimeError(\n\u001b[0m\u001b[0;32m    206\u001b[0m                 'input.size(-1) must be equal to input_size. Expected {}, got {}'.format(\n\u001b[0;32m    207\u001b[0m                     self.input_size, input.size(-1)))\n",
      "\u001b[1;31mRuntimeError\u001b[0m: input.size(-1) must be equal to input_size. Expected 98, got 1"
     ]
    }
   ],
   "source": [
    "trainer.train(dataloader_train, dataloader_val, batch_size=batch_size, n_epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76216d19-9009-4d96-8538-a12b249004e4",
   "metadata": {},
   "source": [
    "<h3>Evaluation</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a6e9c5-755e-4e2a-9a03-41c5e490c051",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "x_batch, y_batch = dataset_val[0:6956]\n",
    "# to do : convert x_batch to tensor and send to gpu \n",
    "x_batch = torch.tensor(x_batch, device=torch.device(\"cuda:0\"))\n",
    "y_pred = trainer.network(x_batch)\n",
    "y_pred = F.softmax(y_pred, dim=1)\n",
    "# to do : convert to np array and vstack it to y_pred\n",
    "y_pred = y_pred.detach().cpu().numpy()\n",
    "y_pred = np.argmax(y_pred, axis=1)\n",
    "dic = {\"y_pred\": y_pred, \"y_true\": y_batch}\n",
    "\n",
    "df = pd.DataFrame(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b45cc3-b4b8-40cc-8885-a35128d2ced6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90d5fd6-27a9-423a-a6c9-3f883c502ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' Accuracy: {sum(df[\"y_pred\"] == df[\"y_true\"])/6956}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59cbd3fa-ed14-4994-a189-facce53fd58f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "# torch.save(model.state_dict(), '../models/lstm3.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63030266-017e-4a9c-9b82-5ccb96c24af7",
   "metadata": {},
   "source": [
    "<h3>Plots</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65a18d77-63d0-4ba4-815c-8299a49a60ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e5fe7023-e147-443c-a5c3-9ccc8fc65d0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LSTMTrainer' object has no attribute 'val_losses'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6524/2063504258.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mval_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_losses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LSTMTrainer' object has no attribute 'val_losses'"
     ]
    }
   ],
   "source": [
    "plt.plot(trainer.val_losses)\n",
    "plt.plot(trainer.train_losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31cd1c48-cc22-475d-97bb-cb2e75584ad2",
   "metadata": {},
   "source": [
    "3 LSTM layer seems to have even better accuracy, could continue optimizing parameters further"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d524ba4-4163-4ced-8eac-81621b702e5f",
   "metadata": {},
   "source": [
    "<h3>Classification Report</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9571c940-ec53-4c24-9865-cb7762afe401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# not a holistic look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38fdbbe-91b8-4925-a986-6069fddb6db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104c8c0e-3183-4653-9ab3-5ca7df08a910",
   "metadata": {},
   "outputs": [],
   "source": [
    "report = sklearn.metrics.classification_report(dic[\"y_true\"], dic[\"y_pred\"], target_names=ligands, output_dict=True)\n",
    "rep = pd.DataFrame(report).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e4e9cf-5639-4bd7-a089-7e174f1b16d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "rep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f73122-1429-4fe9-914a-6f20d6b5bf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion = sklearn.metrics.confusion_matrix(dic[\"y_true\"], dic[\"y_pred\"])\n",
    "plot = sklearn.metrics.ConfusionMatrixDisplay(confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdad146a-91b4-4c17-83b3-a7d414b9b0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedaff90-bf1c-4355-8163-bf6234ad6a13",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
